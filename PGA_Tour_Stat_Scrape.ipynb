{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGA Tour Player Performance: Web Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL of page to be scraped\n",
    "url = 'https://www.pgatour.com/players.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve page with the requests module\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create BeautifulSoup object; parse w 'html.parser'\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scrape Link to Each Player Stat Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #execute chromedriver\n",
    "# executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "# browser = Browser('chrome', **executable_path, headless=False)\n",
    "# browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get html code via beautifulsoup\n",
    "# html = browser.html\n",
    "# soup = BeautifulSoup(html, 'html.parser')\n",
    "#soup.prettify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get names of all the player links\n",
    "#retrieve the parent divs for all links\n",
    "players = soup.find_all('span',class_=\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty list to accept data\n",
    "player_names = []\n",
    "player_url = []\n",
    "\n",
    "#loop through each parent div and grab the link to the player stat page\n",
    "for player in players:\n",
    "    #get name of player\n",
    "    player_names.append(player.a.text)\n",
    "    #get url for player performance page\n",
    "    player_url.append(player.a['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scrape PGA Performance Data for Each Individual Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.pgatour.com/players/player.08793.tiger-woods.html'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create url for player\n",
    "base_url = 'https://www.pgatour.com'\n",
    "test_url = player_url[802]\n",
    "scrape_url = base_url + test_url\n",
    "#scrape_url = \"https://www.pgatour.com/players/player.01006.john-adams.html\"\n",
    "\n",
    "#go to url page\n",
    "response = requests.get(scrape_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "scrape_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splinter Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Browser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8be769a793ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#execute chromedriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mexecutable_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'executable_path'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'chromedriver.exe'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbrowser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBrowser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'chrome'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mexecutable_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheadless\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Browser' is not defined"
     ]
    }
   ],
   "source": [
    "#execute chromedriver\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(scrape_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "browser.click_link_by_partial_text(\"Performance\")\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test to see if javascript rendered data was scraped properly\n",
    "# test = soup.find('div', class_='wrap').find('div', class_='tabbable').find('div', class_=\"performance\").find('div',class_='tab-content') \\\n",
    "# .find('div', class_='tab-pane')\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#photo of player\n",
    "try:\n",
    "    photo_url = soup.find('img', class_='photo')['src']\n",
    "    #player_intro = [{'Player Name':}]\n",
    "except TypeError:\n",
    "    photo_url = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scrape all html hstat code\n",
    "info = soup.findAll('div', class_='item')\n",
    "\n",
    "#headline stats\n",
    "info_stats = []\n",
    "\n",
    "for i in info:\n",
    "    try:\n",
    "        #get stat name\n",
    "        caption = i.find('div',class_='denotation').text\n",
    "        #get stat value\n",
    "        value = i.find('div', class_='value').text\n",
    "        #clean up text\n",
    "        value = value.replace('\\xa0','')\n",
    "        value = value.replace('\\n','')\n",
    "        #save to dictionary\n",
    "        #post = {'caption':caption, 'value': value}\n",
    "        post = {caption: value}\n",
    "        #append to list\n",
    "        info_stats.append(post)\n",
    "    except AttributeError:\n",
    "        nothing = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scrape all html hstat code\n",
    "hstats = soup.findAll('div', class_='stat')\n",
    "\n",
    "#headline stats\n",
    "h_stats = []\n",
    "for hstat in hstats:\n",
    "    try:\n",
    "        #get stat name\n",
    "        caption = hstat.find('div',class_='caption').text\n",
    "        #get stat value\n",
    "        value = hstat.find('div',class_='value').text\n",
    "        \n",
    "        #save to dictionary\n",
    "        #post = {'caption':caption, 'value': value}\n",
    "        post = {caption : value}\n",
    "\n",
    "        #append to list\n",
    "        h_stats.append(post)\n",
    "    except AttributeError:\n",
    "        nothing = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scrape all html astat code\n",
    "astats = soup.findAll('tr')\n",
    "\n",
    "#attribute stats\n",
    "a_stats = []\n",
    "\n",
    "for astat in astats:\n",
    "    try:\n",
    "        #get the stat name\n",
    "        caption = astat.find('td',class_='caption').text\n",
    "        #get stat value\n",
    "        value = astat.find('td',class_='value').text\n",
    "        \n",
    "        #save to dictionary\n",
    "        post = {caption : value}\n",
    "        \n",
    "        #append to list\n",
    "        a_stats.append(post)\n",
    "    except AttributeError:\n",
    "        nothing = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scrape for additional needed info\n",
    "extrastats = soup.findAll('td')\n",
    "\n",
    "#attribute stats\n",
    "extra_stats = []\n",
    "\n",
    "for extra in extrastats:\n",
    "    try:\n",
    "        #get the stat name\n",
    "        text = extra.text\n",
    "        #append to list\n",
    "        extra_stats.append(text)\n",
    "    except AttributeError:\n",
    "        nothing=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these attributes are unique with no captions/values-All string format\n",
    "#search sub_strings of desired variables for values\n",
    "sub_strings = ['Total Left rough', 'Total Right rough', 'Possible Fwys', 'Distance Rank', 'Accuracy Rank',\n",
    "      'Total Club Head Speed', 'Total Attempts']\n",
    "\n",
    "extra_stats_var= []\n",
    "for sub in sub_strings:\n",
    "    x = [s for s in extra_stats if sub in s]\n",
    "    if x:\n",
    "        x = x[0].split(':')\n",
    "        x[1] = x[1].replace(' ','')\n",
    "\n",
    "        #post = {'caption': x[0], 'value': x[1]}\n",
    "        post = {x[0] : x[1]}\n",
    "        extra_stats_var.append(post)\n",
    "    else:\n",
    "        nothing=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#function that takes desired variables with your list of dictionaries scraped and returns a clean list of these variables\n",
    "def get_vars(stats, vars_wanted):\n",
    "    stats_vars = []\n",
    "    items=[]\n",
    "    #iterate through scraped data to find desired variables\n",
    "    for list_item in stats:\n",
    "        dict_item = [key for key,value in list_item.items()]\n",
    "        if dict_item[0] in vars_wanted:\n",
    "            #check for duplicates\n",
    "            if dict_item not in items:\n",
    "                items.append(dict_item)\n",
    "                stats_vars.append(list_item)\n",
    "    return stats_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables wanted from info stats\n",
    "info_var = ['Height', 'Weight', 'AGE', 'Turned Pro', 'College', 'Birthplace' ,'FEDEXCUP Rank', 'FEDEXCUP Points', 'Scoring Average']\n",
    "#variables wanted from headline stats\n",
    "h_var = ['Total Distance', 'Total Drives', '# of Drives', 'Fairways Hit', 'Possible Fairways', 'Measured Rounds']\n",
    "#variables wanted from additional stats\n",
    "a_var = ['Driving Distance','Driving Accuracy Percentage','Total Driving','Club Head Speed',\n",
    "         'Distance from Edge of Fairway','Left Rough Tendency','Right Rough Tendency','Total Driving Efficiency']\n",
    "extra_var = ['Total Left rough', 'Total Right rough', 'Possible Fwys', 'Distance Rank', 'Accuracy Rank',\n",
    "      'Total Club Head Speed', 'Total Attempts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_stats_vars = get_vars(info_stats, info_var)\n",
    "h_stats_vars = get_vars(h_stats, h_var)\n",
    "a_stats_vars = get_vars(a_stats, a_var)\n",
    "extra_stats_vars = get_vars(extra_stats_var, sub_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#combine all stat variables\n",
    "# old method : all_stat_var = info_stats_vars + h_stats_vars + a_stats_vars + extra_stats_vars\n",
    "all_stat_var = {}\n",
    "\n",
    "a_stats_vars = {key: value for a_stat in a_stats_vars for key, value in a_stat.items()}\n",
    "all_stat_var.update(a_stats_vars)\n",
    "\n",
    "h_stats_vars = {key: value for h_stat in h_stats_vars for key, value in h_stat.items()}\n",
    "all_stat_var.update(h_stats_vars)\n",
    "\n",
    "extra_stats_vars = {key: value for extra_stat in extra_stats_vars for key, value in extra_stat.items()}\n",
    "all_stat_var.update(extra_stats_vars)\n",
    "\n",
    "info_stats_vars = {key: value for info_stat in info_stats_vars for key, value in info_stat.items()}\n",
    "all_stat_var.update(info_stats_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "bla = soup.findAll('div', class_ = 'holder')\n",
    "dates_ = soup.findAll('td', class_ = 'date')\n",
    "rounds = soup.findAll('td', class_='round')\n",
    "\n",
    "tourney_name = []\n",
    "all_text = []\n",
    "scores = []\n",
    "to_par = []\n",
    "pos = []\n",
    "dates = []\n",
    "\n",
    "for i in bla:\n",
    "    x = i.find('tbody')\n",
    "    #tourney info\n",
    "    tourneys = x.findAll('p')\n",
    "    #need this for all text\n",
    "    tds = x.findAll('td')\n",
    "    #get all text to use later for pos\n",
    "    [all_text.append(td.text) for td in tds]\n",
    "    \n",
    "    #tournament names\n",
    "    [tourney_name.append(j.text) for j in tourneys]\n",
    "\n",
    "#clean dates\n",
    "[dates.append(d.text) for d in dates_]\n",
    "#scores of each round in increments of 4 ('--' means no score)\n",
    "[scores.append(r.text) for r in rounds]\n",
    "#now append tournament position results by getting list item after tournament name\n",
    "[pos.append(all_text[all_text.index(tourney)+1]) for tourney in tourney_name]\n",
    "#now append tournament position results by getting list item after tournament name\n",
    "[to_par.append(all_text[all_text.index(tourney)+8]) for tourney in tourney_name]\n",
    "#delete first one\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create final dictionary of tournaments for the past year\n",
    "tournament_history = []\n",
    "for date,tourney,score,rank in zip(dates,tourney_name,to_par,pos):\n",
    "    try:\n",
    "        #create dictionary with all info\n",
    "        post = {'Date':date, \n",
    "                'Tournament Name':tourney, \n",
    "                'Total Score':score, \n",
    "                'POS':rank}\n",
    "        #append to final list\n",
    "        tournament_history.append(post)\n",
    "    except AttributeError:\n",
    "        nothing=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#output list\n",
    "player_final = {}\n",
    "player_final['player_intro'] = photo_url\n",
    "player_final['all_stat_var'] = all_stat_var\n",
    "player_final['tournament_hist'] = tournament_history\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titleist Site Web Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute chromedriver\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.titleist.com/tour/pga/players\"\n",
    "base_url = \"https://www.titleist.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#info we will scrape\n",
    "done = 0\n",
    "link = []\n",
    "name = []\n",
    "equipment = []\n",
    "type_equipment = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bjerregaard, Lucas\n",
      "Grace, Branden\n",
      "Stanley, Kyle\n",
      "HowellIII, Charles\n",
      "Na, Kevin\n",
      "Olesen, Thorbjorn\n",
      "TsungPan, Cheng\n",
      "Mitchell, Keith\n",
      "HunAn, Byeong-\n",
      "JaeIm, Sung-\n",
      "Reavie, Chez\n",
      "Ancer, Abraham\n",
      "Kokrak, Jason\n",
      "Lewis, Tom\n",
      "Hoffman, Charley\n",
      "Westwood, Lee\n",
      "Imahira, Shugo\n",
      "Luiten, Joost\n",
      "List, Luke\n",
      "Palmer, Ryan\n",
      "Moore, Ryan\n",
      "Kodaira, Satoshi\n",
      "Vegas, Jhonattan\n",
      "Dahmen, Joel\n",
      "Glover, Lucas\n",
      "Conners, Corey\n",
      "Piercy, Scott\n",
      "Johnson, Zach\n",
      "Harman, Brian\n",
      "Hadley, Chesson\n",
      "Perez, Pat\n",
      "Kizzire, Patton\n",
      "Norris, Shaun\n",
      "Tway, Kevin\n",
      "Homa, Max\n",
      "Chappell, Kevin\n",
      "Walker, Jimmy\n",
      "Thompson, Michael\n",
      "Fisher, Ross\n",
      "Cink, Stewart\n",
      "Armour, Ryan\n",
      "Lee, Danny\n",
      "Long, Adam\n",
      "Levy, Alexander\n",
      "Schwartzel, Charl\n",
      "Streelman, Kevin\n",
      "Landry, Andrew\n",
      "Stallings, Scott\n",
      "Wood, Chris\n",
      "Wood, Chris\n",
      "Gay, Brian\n",
      "Uihlein, Peter\n",
      "Niemann, Joaquin\n",
      "Bhullar, Gaganjeet\n",
      "Stone, Brandon\n",
      "Dunne, Paul\n",
      "Cook, Austin\n",
      "Henley, Russell\n"
     ]
    }
   ],
   "source": [
    "while done != 1:\n",
    "    try:\n",
    "        browser.click_link_by_partial_text(\"Next\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "        html = browser.html\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        #scrape all html hstat code\n",
    "        test = soup.findAll('li', class_='m-results-item')\n",
    "        \n",
    "        for t in test:\n",
    "            #link to clubs using\n",
    "            l = t.find('h2', class_='m-results-label').a['href']\n",
    "            #name of player\n",
    "            n = t.find('h2', class_='m-results-label').text\n",
    "            #format name to match other data scraped\n",
    "            n = n.replace(' ', '')\n",
    "            n = n.replace('\\n', '')\n",
    "            isupper = [letter.isupper() for letter in n]\n",
    "            n = n + \", \"\n",
    "            #index of last name starting\n",
    "            last_name_index = [i for i, x in enumerate(isupper) if x][1]\n",
    "            #break up\n",
    "            first_name = n[0:last_name_index]\n",
    "            last_name = n[last_name_index:]\n",
    "            n = last_name + first_name\n",
    "            print(n)\n",
    "            \n",
    "            \n",
    "            #equipment using\n",
    "            e = t.find('em').text\n",
    "    \n",
    "            link.append(l)\n",
    "            name.append(n)\n",
    "            equipment.append(e)\n",
    "            \n",
    "            if e == 'Brand Ambassador':\n",
    "                club_url = base_url + l\n",
    "                browser.visit(club_url)\n",
    "                html = browser.html\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                driver = soup.find('div', class_ = \"m-category-listing-content\").a.text\n",
    "                driver = driver.replace(\" \", \"\")\n",
    "                driver = driver.replace(\"\\n\", \"\")\n",
    "                type_equipment.append(driver)\n",
    "                browser.back()\n",
    "            else:\n",
    "                golf_ball = t.findAll('p')\n",
    "                for b in golf_ball:\n",
    "                    ball = [b.text for b in golf_ball]\n",
    "                    ball = ball[1]\n",
    "                    ball = ball.replace(\"Golf Ball Player\", \"\")\n",
    "                    type_equipment.append(ball)\n",
    "    except:\n",
    "        done=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bjerregaard, Lucas\n",
      "Grace, Branden\n",
      "Stanley, Kyle\n",
      "HowellIII, Charles\n",
      "Na, Kevin\n",
      "Olesen, Thorbjorn\n",
      "TsungPan, Cheng\n",
      "Mitchell, Keith\n",
      "HunAn, Byeong-\n",
      "JaeIm, Sung-\n",
      "Reavie, Chez\n",
      "Ancer, Abraham\n",
      "Kokrak, Jason\n",
      "Lewis, Tom\n",
      "Hoffman, Charley\n",
      "Westwood, Lee\n",
      "Imahira, Shugo\n",
      "Luiten, Joost\n",
      "List, Luke\n",
      "Palmer, Ryan\n",
      "Moore, Ryan\n",
      "Kodaira, Satoshi\n",
      "Vegas, Jhonattan\n",
      "Dahmen, Joel\n",
      "Glover, Lucas\n",
      "Conners, Corey\n",
      "Piercy, Scott\n",
      "Johnson, Zach\n",
      "Harman, Brian\n",
      "Hadley, Chesson\n",
      "Perez, Pat\n",
      "Kizzire, Patton\n",
      "Norris, Shaun\n",
      "Tway, Kevin\n",
      "Homa, Max\n",
      "Chappell, Kevin\n",
      "Walker, Jimmy\n",
      "Thompson, Michael\n",
      "Fisher, Ross\n",
      "Cink, Stewart\n",
      "Armour, Ryan\n",
      "Lee, Danny\n",
      "Long, Adam\n",
      "Levy, Alexander\n",
      "Schwartzel, Charl\n",
      "Streelman, Kevin\n",
      "Landry, Andrew\n",
      "Stallings, Scott\n",
      "Wood, Chris\n",
      "Wood, Chris\n",
      "Gay, Brian\n",
      "Uihlein, Peter\n",
      "Niemann, Joaquin\n",
      "Bhullar, Gaganjeet\n",
      "Stone, Brandon\n",
      "Dunne, Paul\n",
      "Cook, Austin\n",
      "Henley, Russell\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-057250c8aa7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;31m#link to clubs using\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'm-results-label'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[1;31m#name of player\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'm-results-label'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for x in range(5):\n",
    "        browser.click_link_by_partial_text(\"Next\")\n",
    "        time.sleep(1)\n",
    "        \n",
    "        html = browser.html\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        #scrape all html hstat code\n",
    "        test = soup.findAll('li', class_='m-results-item')\n",
    "        \n",
    "        for t in test:\n",
    "            #link to clubs using\n",
    "            l = t.find('h2', class_='m-results-label').a['href']\n",
    "            #name of player\n",
    "            n = t.find('h2', class_='m-results-label').text\n",
    "            #format name to match other data scraped\n",
    "            n = n.replace(' ', '')\n",
    "            n = n.replace('\\n', '')\n",
    "            isupper = [letter.isupper() for letter in n]\n",
    "            n = n + \", \"\n",
    "            #index of last name starting\n",
    "            last_name_index = [i for i, x in enumerate(isupper) if x][1]\n",
    "            #break up\n",
    "            first_name = n[0:last_name_index]\n",
    "            last_name = n[last_name_index:]\n",
    "            n = last_name + first_name\n",
    "            print(n)\n",
    "            \n",
    "            #equipment using\n",
    "            e = t.find('em').text\n",
    "    \n",
    "            link.append(l)\n",
    "            #name.append(n)\n",
    "            equipment.append(e)\n",
    "            \n",
    "            if e == 'Brand Ambassador':\n",
    "                club_url = base_url + l\n",
    "                browser.visit(club_url)\n",
    "                html = browser.html\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                driver = soup.find('div', class_ = \"m-category-listing-content\").a.text\n",
    "                driver = driver.replace(\" \", \"\")\n",
    "                driver = driver.replace(\"\\n\", \"\")\n",
    "                type_equipment.append(driver)\n",
    "                browser.back()\n",
    "            else:\n",
    "                golf_ball = t.findAll('p')\n",
    "                ball = [b.text for b in golf_ball]\n",
    "                ball = ball[1]\n",
    "                ball = ball.replace(\"Golf Ball Player\", \"\")\n",
    "                type_equipment.append(ball)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n                                Lucas Bjerregaard\\n                                    \\n',\n",
       " '\\n\\n                                Branden Grace\\n                                    \\n']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = name[0]\n",
    "test = test.replace(' ', '')\n",
    "test = test.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test + \", \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_name = test[0:last_name_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_name = test[last_name_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_name = last_name + first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thomas, Justin'"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thomas, '"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Justin'"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[2].islower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "isupper = [letter.isupper() for letter in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_name_index = [i for i, x in enumerate(isupper) if x][1]\n",
    "last_name_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'islower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-331-513a9ba9dcdf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mfirst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mletter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mletter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mletter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mletter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mislower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mfirst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mletter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'bool' object has no attribute 'islower'"
     ]
    }
   ],
   "source": [
    "first = []\n",
    "last = []\n",
    "for letter in test:\n",
    "    if letter.isupper():\n",
    "        first.append(letter)\n",
    "        letter = letter.islower()\n",
    "    while(letter.islower()):\n",
    "        first.append(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "upper = []\n",
    "lower = []\n",
    "for letter in test:\n",
    "    print(letter.islower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape all html hstat code\n",
    "test = soup.findAll('li', class_='m-results-item')\n",
    "link = []\n",
    "name = []\n",
    "equipment = []\n",
    "\n",
    "for t in test:\n",
    "    l = t.find('h2', class_='m-results-label').a['href']\n",
    "    n = t.find('h2', class_='m-results-label').text\n",
    "    e = t.find('em').text\n",
    "    \n",
    "    link.append(l)\n",
    "    name.append(n)\n",
    "    equipment.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<li class=\"m-results-item\">\n",
       "<div class=\"m-results-media\">\n",
       "<a href=\"/tour/2778/branden-grace\">\n",
       "<picture>\n",
       "<source srcset=\"//acushnet.scene7.com/is/image/titleist/player_100x100?$player=titleist/2016_branden_grace_thumbnail, //acushnet.scene7.com/is/image/titleist/player_200x200?$player=titleist/2016_branden_grace_thumbnail 2x\"/>\n",
       "<img alt=\"Branden Grace\" src=\"//acushnet.scene7.com/is/image/titleist/player_100x100?$player=titleist/2016_branden_grace_thumbnail\"/>\n",
       "</picture>\n",
       "</a>\n",
       "</div><!--/.m-results-media-->\n",
       "<div class=\"m-results-content\">\n",
       "<p class=\"titleist-tag\">\n",
       "<a href=\"/tour/all-players?tour=PGA\">PGA</a>\n",
       "</p>\n",
       "<h2 class=\"m-results-label\">\n",
       "<a href=\"/tour/2778/branden-grace\">\n",
       "                                Branden Grace\n",
       "                                    </a>\n",
       "</h2>\n",
       "<p><em>Golf Ball Player<br/></em>Titleist Pro V1x </p>\n",
       "<p>World Rank: 46</p>\n",
       "</div><!--/.m-results-content-->\n",
       "</li>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_[0] == 'Brand Ambassador'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = t.findAll('p')\n",
    "ball = []\n",
    "ball = [b.text for b in bla]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Titleist Pro V1x '"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ball = ball[1]\n",
    "ball = ball.replace(\"Golf Ball Player\", \"\")\n",
    "ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "newstr = exstring.replace(\"Golf Ball Player\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Titleist Pro V1x '"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(\"https://www.titleist.com/tour/2778/branden-grace\")\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-e0ca32933fc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbla\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"m-category-listing-content\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbla\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "bla = soup.find('div', class_ = \"m-category-listing-content\").a.text\n",
    "bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bla' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-047595d0fae9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbla\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'bla' is not defined"
     ]
    }
   ],
   "source": [
    "bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = bla.replace(\" \", \"\")\n",
    "bla = bla.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'917D2Driver'"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
