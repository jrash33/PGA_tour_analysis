{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PGA Tour Player Performance: Web Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL of page to be scraped\n",
    "url = 'https://www.pgatour.com/players.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve page with the requests module\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create BeautifulSoup object; parse w 'html.parser'\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scrape Link to Each Player Stat Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get names of all the player links\n",
    "#retrieve the parent divs for all links\n",
    "players = soup.find_all('span',class_=\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty list to accept data\n",
    "player_names = []\n",
    "player_url = []\n",
    "\n",
    "#loop through each parent div and grab the link to the player stat page\n",
    "for player in players:\n",
    "    #get name of player\n",
    "    player_names.append(player.a.text)\n",
    "    #get url for player performance page\n",
    "    player_url.append(player.a['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scrape PGA Performance Data for Each Individual Player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.pgatour.com/players/player.01006.john-adams.html'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create url for player\n",
    "base_url = 'https://www.pgatour.com'\n",
    "test_url = player_url[0]\n",
    "scrape_url = base_url + test_url\n",
    "#scrape_url = \"https://www.pgatour.com/players/player.01006.john-adams.html\"\n",
    "\n",
    "#go to url page\n",
    "response = requests.get(scrape_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "scrape_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splinter Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute chromedriver\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(scrape_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "browser.click_link_by_partial_text(\"Performance\")\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html = browser.html\n",
    "# soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropdown = browser.find_by_xpath(\"//div[@class='select year']//select[@class='hasCustomSelect']\")\n",
    "# for option in dropdown.find_by_tag('option'):\n",
    "#     option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#photo of player\n",
    "try:\n",
    "    photo_url = soup.find('img', class_='photo')['src']\n",
    "    #player_intro = [{'Player Name':}]\n",
    "except TypeError:\n",
    "    photo_url = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scrape all html hstat code\n",
    "info = soup.findAll('div', class_='item')\n",
    "\n",
    "#headline stats\n",
    "info_stats = []\n",
    "\n",
    "for i in info:\n",
    "    try:\n",
    "        #get stat name\n",
    "        caption = i.find('div',class_='denotation').text\n",
    "        #get stat value\n",
    "        value = i.find('div', class_='value').text\n",
    "        #clean up text\n",
    "        value = value.replace('\\xa0','')\n",
    "        value = value.replace('\\n','')\n",
    "        #save to dictionary\n",
    "        #post = {'caption':caption, 'value': value}\n",
    "        post = {caption: value}\n",
    "        #append to list\n",
    "        info_stats.append(post)\n",
    "    except AttributeError:\n",
    "        nothing = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dropdown = browser.find_by_xpath(\"//div[@class='select year']//select[@class='hasCustomSelect']\")\n",
    "h_stats_all = []\n",
    "a_stats_all = []\n",
    "extra_stats_var_all = []\n",
    "for option in dropdown.find_by_tag('option'):  \n",
    "    option.click()\n",
    "    time.sleep(1)\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    #scrape all html hstat code\n",
    "    hstats = soup.findAll('div', class_='stat')\n",
    "\n",
    "    #headline stats\n",
    "    h_stats = []\n",
    "    year = {\"year\":option.text}\n",
    "    h_stats.append(year)\n",
    "    \n",
    "    for hstat in hstats:\n",
    "        try:\n",
    "            #get stat name\n",
    "            caption = hstat.find('div',class_='caption').text\n",
    "            #get stat value\n",
    "            value = hstat.find('div',class_='value').text\n",
    "\n",
    "            #save to dictionary\n",
    "            #post = {'caption':caption, 'value': value}\n",
    "            post = {caption : value}\n",
    "\n",
    "            #append to list\n",
    "            h_stats.append(post)\n",
    "        except AttributeError:\n",
    "            nothing = 0\n",
    "            \n",
    "    h_stats_all.append(h_stats)\n",
    "\n",
    "    #scrape all html astat code\n",
    "    astats = soup.findAll('tr')\n",
    "\n",
    "    #attribute stats\n",
    "    a_stats = []\n",
    "    year = {\"year\":option.text}\n",
    "    a_stats.append(year)\n",
    "\n",
    "    for astat in astats:\n",
    "        try:\n",
    "            #get the stat name\n",
    "            caption = astat.find('td',class_='caption').text\n",
    "            #get stat value\n",
    "            value = astat.find('td',class_='value').text\n",
    "\n",
    "            #save to dictionary\n",
    "            post = {caption : value}\n",
    "\n",
    "            #append to list\n",
    "            a_stats.append(post)\n",
    "        except AttributeError:\n",
    "            nothing = 0\n",
    "    \n",
    "    a_stats_all.append(a_stats)\n",
    "    \n",
    "    #scrape for additional needed info\n",
    "    extrastats = soup.findAll('td')\n",
    "\n",
    "    #attribute stats\n",
    "    extra_stats = []\n",
    "\n",
    "\n",
    "\n",
    "    for extra in extrastats:\n",
    "        try:\n",
    "            #get the stat name\n",
    "            text = extra.text\n",
    "            #append to list\n",
    "            extra_stats.append(text)\n",
    "        except AttributeError:\n",
    "            nothing=0\n",
    "            \n",
    "    #these attributes are unique with no captions/values-All string format\n",
    "    #search sub_strings of desired variables for values\n",
    "    sub_strings = ['Total Left rough', 'Total Right rough', 'Possible Fwys', 'Distance Rank', 'Accuracy Rank',\n",
    "          'Total Club Head Speed', 'Total Attempts']\n",
    "    extra_stats_var= []\n",
    "    year = {\"year\":option.text}\n",
    "    extra_stats_var.append(year)\n",
    "    for sub in sub_strings:\n",
    "        x = [s for s in extra_stats if sub in s]\n",
    "        if x:\n",
    "            x = x[0].split(':')\n",
    "            x[1] = x[1].replace(' ','')\n",
    "\n",
    "            #post = {'caption': x[0], 'value': x[1]}\n",
    "            post = {x[0] : x[1]}\n",
    "            extra_stats_var.append(post)\n",
    "        else:\n",
    "            nothing=0\n",
    "            \n",
    "    extra_stats_var_all.append(extra_stats_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_vars(stats, vars_wanted):\n",
    "    stats_vars = []\n",
    "    items=[]\n",
    "    #iterate through scraped data to find desired variables\n",
    "    for list_item in stats:\n",
    "        dict_item = [key for key,value in list_item.items()]\n",
    "        if dict_item[0] in vars_wanted:\n",
    "            #check for duplicates\n",
    "            if dict_item not in items:\n",
    "                items.append(dict_item)\n",
    "                stats_vars.append(list_item)\n",
    "    return stats_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables wanted from info stats\n",
    "info_var = ['year','Height', 'Weight', 'AGE', 'Turned Pro', 'College', 'Birthplace' ,'FEDEXCUP Rank', 'FEDEXCUP Points', 'Scoring Average']\n",
    "#variables wanted from headline stats\n",
    "h_var = ['year','Total Distance', 'Total Drives', '# of Drives', 'Fairways Hit', 'Possible Fairways', 'Measured Rounds']\n",
    "#variables wanted from additional stats\n",
    "a_var = ['year','Driving Distance','Driving Accuracy Percentage','Total Driving','Club Head Speed',\n",
    "         'Distance from Edge of Fairway','Left Rough Tendency','Right Rough Tendency','Total Driving Efficiency']\n",
    "extra_var = ['year','Total Left rough', 'Total Right rough', 'Possible Fwys', 'Distance Rank', 'Accuracy Rank',\n",
    "          'Total Club Head Speed', 'Total Attempts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_stats_vars = get_vars(info_stats, info_var)\n",
    "h_stats_vars = [get_vars(h_stats, h_var) for h_stats in h_stats_all]\n",
    "a_stats_vars = [get_vars(a_stats, a_var) for a_stats in a_stats_all]\n",
    "extra_stats_vars = [get_vars(extra_stats, extra_var) for extra_stats in extra_stats_var_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_stats_vars = {key: value for info_stat in info_stats_vars for key, value in info_stat.items()}\n",
    "#all years of stats\n",
    "a_stats_vars = [{key: value for a_stat in list_item for key, value in a_stat.items()} for list_item in a_stats_vars]\n",
    "h_stats_vars = [{key: value for a_stat in list_item for key, value in a_stat.items()} for list_item in h_stats_vars]\n",
    "extra_stats_vars = [{key: value for a_stat in list_item for key, value in a_stat.items()} for list_item in extra_stats_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stat_var =[]\n",
    "\n",
    "for a_stat, h_stat, extra_stat in zip(a_stats_vars, h_stats_vars, extra_stats_vars):\n",
    "    temp_dict = {}\n",
    "    temp_dict.update(a_stat)\n",
    "    temp_dict.update(h_stat)\n",
    "    temp_dict.update(extra_stat)\n",
    "    \n",
    "    all_stat_var.append(temp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "bla = soup.findAll('div', class_ = 'holder')\n",
    "dates_ = soup.findAll('td', class_ = 'date')\n",
    "rounds = soup.findAll('td', class_='round')\n",
    "\n",
    "tourney_name = []\n",
    "all_text = []\n",
    "scores = []\n",
    "to_par = []\n",
    "pos = []\n",
    "dates = []\n",
    "\n",
    "for i in bla:\n",
    "    x = i.find('tbody')\n",
    "    #tourney info\n",
    "    tourneys = x.findAll('p')\n",
    "    #need this for all text\n",
    "    tds = x.findAll('td')\n",
    "    #get all text to use later for pos\n",
    "    [all_text.append(td.text) for td in tds]\n",
    "    \n",
    "    #tournament names\n",
    "    [tourney_name.append(j.text) for j in tourneys]\n",
    "\n",
    "#clean dates\n",
    "[dates.append(d.text) for d in dates_]\n",
    "#scores of each round in increments of 4 ('--' means no score)\n",
    "[scores.append(r.text) for r in rounds]\n",
    "#now append tournament position results by getting list item after tournament name\n",
    "[pos.append(all_text[all_text.index(tourney)+1]) for tourney in tourney_name]\n",
    "#now append tournament position results by getting list item after tournament name\n",
    "[to_par.append(all_text[all_text.index(tourney)+8]) for tourney in tourney_name]\n",
    "#delete first one\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create final dictionary of tournaments for the past year\n",
    "tournament_history = []\n",
    "for date,tourney,score,rank in zip(dates,tourney_name,to_par,pos):\n",
    "    try:\n",
    "        #create dictionary with all info\n",
    "        post = {'Date':date, \n",
    "                'Tournament Name':tourney, \n",
    "                'Total Score':score, \n",
    "                'POS':rank}\n",
    "        #append to final list\n",
    "        tournament_history.append(post)\n",
    "    except AttributeError:\n",
    "        nothing=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#output list\n",
    "player_final = {}\n",
    "player_final['player_intro'] = photo_url\n",
    "player_final['info'] = info_stats_vars\n",
    "player_final['all_stat_var'] = all_stat_var\n",
    "player_final['tournament_hist'] = tournament_history\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titleist Site Web Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute chromedriver\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.titleist.com/tour/pga/players\"\n",
    "base_url = \"https://www.titleist.com\"\n",
    "browser.visit(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close pop-up\n",
    "try:\n",
    "    browser.find_by_css(\"Button\")[11].click()\n",
    "except:\n",
    "    print(\"No Pop Up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#info we will scrape\n",
    "done = 0\n",
    "titleist_players = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while done != 1:\n",
    "    try:\n",
    "#         browser.click_link_by_partial_text(\"Next\")\n",
    "#         time.sleep(1)\n",
    "        \n",
    "        html = browser.html\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        #scrape all html hstat code\n",
    "        test = soup.findAll('li', class_='m-results-item')\n",
    "        \n",
    "        for t in test:\n",
    "\n",
    "            #name of player\n",
    "            n = t.find('h2', class_='m-results-label').text\n",
    "            #format name to match other data scraped\n",
    "            n = n.replace(' ', '')\n",
    "            n = n.replace('\\n', '')\n",
    "            isupper = [letter.isupper() for letter in n]\n",
    "            n = n + \", \"\n",
    "            #index of last name starting\n",
    "            last_name_index = [i for i, x in enumerate(isupper) if x][1]\n",
    "            #break up\n",
    "            first_name = n[0:last_name_index]\n",
    "            last_name = n[last_name_index:]\n",
    "            n = last_name + first_name\n",
    "            name = n\n",
    "\n",
    "            #equipment using\n",
    "            e = t.find('em').text\n",
    "            #name.append(n)\n",
    "            equipment = e\n",
    "\n",
    "            if e == 'Brand Ambassador':\n",
    "                player_page = t.find('h2', class_='m-results-label').a['href']\n",
    "                club_url = base_url + player_page\n",
    "                browser.visit(club_url)\n",
    "                html = browser.html\n",
    "                soup = BeautifulSoup(html, 'html.parser')\n",
    "                try:\n",
    "                    driver = soup.find('div', class_ = \"m-category-listing-content\").a.text\n",
    "                    driver = driver.replace(\" \", \"\")\n",
    "                    driver = driver.replace(\"\\n\", \"\")\n",
    "                    type_equipment = driver\n",
    "                    browser.back()\n",
    "                except:\n",
    "                    golf_ball = t.findAll('p')\n",
    "                    ball = [b.text for b in golf_ball]\n",
    "                    ball = ball[1]\n",
    "                    ball = ball.replace(\"Brand Ambassador\", \"\")\n",
    "                    type_equipment = ball\n",
    "                    browser.back()\n",
    "            else:\n",
    "                golf_ball = t.findAll('p')\n",
    "                ball = [b.text for b in golf_ball]\n",
    "                ball = ball[1]\n",
    "                ball = ball.replace(\"Golf Ball Player\", \"\")\n",
    "                type_equipment = ball\n",
    "            \n",
    "            #put needed info to dictionary\n",
    "            post = {'Player Name': n, \n",
    "            'Type': equipment, \n",
    "            'Equipment': type_equipment, \n",
    "            }\n",
    "            \n",
    "            #append each player to list\n",
    "            if (post['Type'] == \"Brand Ambassador\"):\n",
    "                titleist_players.append(post)\n",
    "                    \n",
    "        browser.click_link_by_partial_text(\"Next\")\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        done=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in titleist_players:\n",
    "    print(i['Player Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEBUGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#execute chromedriver\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.titleist.com/tour/pga/players?page=11\"\n",
    "base_url = \"https://www.titleist.com\"\n",
    "browser.visit(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#close pop-up\n",
    "try:\n",
    "    browser.find_by_css(\"Button\")[11].click()\n",
    "except:\n",
    "    print(\"No Pop Up\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "equipment = []\n",
    "type_equipment = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for x in range(5):\n",
    "#         browser.click_link_by_partial_text(\"Next\")\n",
    "#         time.sleep(1)\n",
    "    \n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "#scrape all html hstat code\n",
    "test = soup.findAll('li', class_='m-results-item')\n",
    "        \n",
    "for t in test:\n",
    "    \n",
    "    #name of player\n",
    "    n = t.find('h2', class_='m-results-label').text\n",
    "    #format name to match other data scraped\n",
    "    n = n.replace(' ', '')\n",
    "    n = n.replace('\\n', '')\n",
    "    isupper = [letter.isupper() for letter in n]\n",
    "    n = n + \", \"\n",
    "    #index of last name starting\n",
    "    last_name_index = [i for i, x in enumerate(isupper) if x][1]\n",
    "    #break up\n",
    "    first_name = n[0:last_name_index]\n",
    "    last_name = n[last_name_index:]\n",
    "    n = last_name + first_name\n",
    "    name.append(n)\n",
    "            \n",
    "    #equipment using\n",
    "    e = t.find('em').text\n",
    "    #name.append(n)\n",
    "    equipment.append(e)\n",
    "            \n",
    "    if e == 'Brand Ambassador':\n",
    "        player_page = t.find('h2', class_='m-results-label').a['href']\n",
    "        club_url = base_url + player_page\n",
    "        browser.visit(club_url)\n",
    "        html = browser.html\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        try:\n",
    "            driver = soup.find('div', class_ = \"m-category-listing-content\").a.text\n",
    "            driver = driver.replace(\" \", \"\")\n",
    "            driver = driver.replace(\"\\n\", \"\")\n",
    "            type_equipment.append(driver)\n",
    "            browser.back()\n",
    "        except:\n",
    "            golf_ball = t.findAll('p')\n",
    "            ball = [b.text for b in golf_ball]\n",
    "            ball = ball[1]\n",
    "            ball = ball.replace(\"Brand Ambassador\", \"\")\n",
    "            print(ball)\n",
    "            type_equipment.append(ball)\n",
    "            browser.back()  \n",
    "    else:\n",
    "        golf_ball = t.findAll('p')\n",
    "        ball = [b.text for b in golf_ball]\n",
    "        ball = ball[1]\n",
    "        ball = ball.replace(\"Golf Ball Player\", \"\")\n",
    "        type_equipment.append(ball)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = name[0]\n",
    "test = test.replace(' ', '')\n",
    "test = test.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test + \", \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_name = test[0:last_name_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_name = test[last_name_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_name = last_name + first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[2].islower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isupper = [letter.isupper() for letter in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_name_index = [i for i, x in enumerate(isupper) if x][1]\n",
    "last_name_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = []\n",
    "last = []\n",
    "for letter in test:\n",
    "    if letter.isupper():\n",
    "        first.append(letter)\n",
    "        letter = letter.islower()\n",
    "    while(letter.islower()):\n",
    "        first.append(letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "upper = []\n",
    "lower = []\n",
    "for letter in test:\n",
    "    print(letter.islower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape all html hstat code\n",
    "test = soup.findAll('li', class_='m-results-item')\n",
    "link = []\n",
    "name = []\n",
    "equipment = []\n",
    "\n",
    "for t in test:\n",
    "    l = t.find('h2', class_='m-results-label').a['href']\n",
    "    n = t.find('h2', class_='m-results-label').text\n",
    "    e = t.find('em').text\n",
    "    \n",
    "    link.append(l)\n",
    "    name.append(n)\n",
    "    equipment.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_[0] == 'Brand Ambassador'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = t.findAll('p')\n",
    "ball = []\n",
    "ball = [b.text for b in bla]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ball = ball[1]\n",
    "ball = ball.replace(\"Golf Ball Player\", \"\")\n",
    "ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newstr = exstring.replace(\"Golf Ball Player\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(\"https://www.titleist.com/tour/2778/branden-grace\")\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = soup.find('div', class_ = \"m-category-listing-content\").a.text\n",
    "bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = bla.replace(\" \", \"\")\n",
    "bla = bla.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
